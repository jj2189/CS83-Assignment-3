{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNCxEW+fK0YWIe5ggQAyc8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jj2189/CS83-Assignment-3/blob/main/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "budhswhvwI2G",
        "outputId": "f1863734-900b-4918-b673-c20d045cfb82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for f in os.listdir('/content/drive/MyDrive'):\n",
        "    print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaBbAhJ1yEOh",
        "outputId": "ef44a1d6-da35-4149-b46f-71004abf0129"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jessica_jiang_headshot.jpg\n",
            "Robustness of Small Random Graphs.pptx\n",
            "Colab Notebooks\n",
            "Untitled document.gdoc\n",
            "image004.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = r'/content/drive/MyDrive/COSC83-spring24-25-student-main (6).zip'\n",
        "extract_path = r'/content/drive/MyDrive/COSC83-spring24-25-student-main (6)'\n",
        "\n",
        "if not os.path.exists(extract_path):  # unzip only if not already done\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n"
      ],
      "metadata": {
        "id": "IKfJtNoHwbxD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_data_dir = '/content/drive/MyDrive/dataset'\n"
      ],
      "metadata": {
        "id": "goaw78pgweDS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3')"
      ],
      "metadata": {
        "id": "BtTBwe9Zzxi4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train/train_faster_rcnn.py --config config/voc.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_mfKhCc0WNy",
        "outputId": "3d6bc606-1b3f-4110-b387-fcd58d4a64e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dataset_params': {'im_train_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/VOCdevkit/VOC2007/JPEGImages', 'ann_train_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/VOCdevkit/VOC2007/Annotations', 'im_test_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007-test/VOCdevkit/VOC2007/JPEGImages', 'ann_test_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007-test/VOCdevkit/VOC2007/Annotations', 'num_classes': 21}, 'model_params': {'im_channels': 3, 'aspect_ratios': [0.5, 1, 2], 'scales': [128, 256, 512], 'min_im_size': 600, 'max_im_size': 1000, 'backbone_out_channels': 512, 'fc_inner_dim': 1024, 'rpn_bg_threshold': 0.3, 'rpn_fg_threshold': 0.7, 'rpn_nms_threshold': 0.7, 'rpn_train_prenms_topk': 12000, 'rpn_test_prenms_topk': 6000, 'rpn_train_topk': 2000, 'rpn_test_topk': 300, 'rpn_batch_size': 256, 'rpn_pos_fraction': 0.5, 'roi_iou_threshold': 0.5, 'roi_low_bg_iou': 0.0, 'roi_pool_size': 7, 'roi_nms_threshold': 0.3, 'roi_topk_detections': 100, 'roi_score_threshold': 0.05, 'roi_batch_size': 128, 'roi_pos_fraction': 0.25}, 'train_params': {'task_name': 'voc', 'seed': 1111, 'acc_steps': 1, 'num_epochs': 4, 'lr_steps': [12, 16], 'lr': 0.001, 'ckpt_name': 'faster_rcnn_voc2007.pth'}}\n",
            "{0: 'background', 1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat', 5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair', 10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse', 14: 'motorbike', 15: 'person', 16: 'pottedplant', 17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor'}\n",
            "100% 5011/5011 [00:45<00:00, 110.60it/s]\n",
            "Total 5011 images found\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Checkpoint voc/faster_rcnn_voc2007.pth exists but does not have 'model_state_dict'. Starting fresh training.\n",
            "starting epoch 0\n",
            "100% 5011/5011 [12:26<00:00,  6.72it/s]\n",
            "Finished epoch 0\n",
            "RPN Classification Loss : 0.2915 | RPN Localization Loss : 0.1340 | FRCNN Classification Loss : 0.4314 | FRCNN Localization Loss : 0.0857\n",
            "starting epoch 1\n",
            "100% 5011/5011 [12:36<00:00,  6.63it/s]\n",
            "Finished epoch 1\n",
            "RPN Classification Loss : 0.2167 | RPN Localization Loss : 0.1179 | FRCNN Classification Loss : 0.2936 | FRCNN Localization Loss : 0.0764\n",
            "starting epoch 2\n",
            "100% 5011/5011 [12:35<00:00,  6.63it/s]\n",
            "Finished epoch 2\n",
            "RPN Classification Loss : 0.1892 | RPN Localization Loss : 0.1116 | FRCNN Classification Loss : 0.2557 | FRCNN Localization Loss : 0.0698\n",
            "starting epoch 3\n",
            "100% 5011/5011 [12:35<00:00,  6.63it/s]\n",
            "Finished epoch 3\n",
            "RPN Classification Loss : 0.1702 | RPN Localization Loss : 0.1083 | FRCNN Classification Loss : 0.2316 | FRCNN Localization Loss : 0.0662\n",
            "Done Training...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_SNbdp48mNuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python test/test_faster_rcnn.py --evaluate True --infer_samples True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3iAOM62LYwR",
        "outputId": "ae63edd4-da8b-40f2-fc18-cc60f76d5791"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "{'dataset_params': {'im_train_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/VOCdevkit/VOC2007/JPEGImages', 'ann_train_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/VOCdevkit/VOC2007/Annotations', 'im_test_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007-test/VOCdevkit/VOC2007/JPEGImages', 'ann_test_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007-test/VOCdevkit/VOC2007/Annotations', 'num_classes': 21}, 'model_params': {'im_channels': 3, 'aspect_ratios': [0.5, 1, 2], 'scales': [128, 256, 512], 'min_im_size': 600, 'max_im_size': 1000, 'backbone_out_channels': 512, 'fc_inner_dim': 1024, 'rpn_bg_threshold': 0.3, 'rpn_fg_threshold': 0.7, 'rpn_nms_threshold': 0.7, 'rpn_train_prenms_topk': 12000, 'rpn_test_prenms_topk': 6000, 'rpn_train_topk': 2000, 'rpn_test_topk': 300, 'rpn_batch_size': 256, 'rpn_pos_fraction': 0.5, 'roi_iou_threshold': 0.5, 'roi_low_bg_iou': 0.0, 'roi_pool_size': 7, 'roi_nms_threshold': 0.3, 'roi_topk_detections': 100, 'roi_score_threshold': 0.05, 'roi_batch_size': 128, 'roi_pos_fraction': 0.25}, 'train_params': {'task_name': 'voc', 'seed': 1111, 'acc_steps': 1, 'num_epochs': 4, 'lr_steps': [12, 16], 'lr': 0.001, 'ckpt_name': 'faster_rcnn_voc2007.pth'}}\n",
            "{0: 'background', 1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat', 5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair', 10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse', 14: 'motorbike', 15: 'person', 16: 'pottedplant', 17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor'}\n",
            "100% 4952/4952 [00:43<00:00, 113.28it/s]\n",
            "Total 4952 images found\n",
            "Looking for model at: voc/faster_rcnn_voc2007.pth\n",
            "100% 10/10 [00:02<00:00,  4.92it/s]\n",
            "{'dataset_params': {'im_train_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/VOCdevkit/VOC2007/JPEGImages', 'ann_train_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/VOCdevkit/VOC2007/Annotations', 'im_test_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007-test/VOCdevkit/VOC2007/JPEGImages', 'ann_test_path': '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007-test/VOCdevkit/VOC2007/Annotations', 'num_classes': 21}, 'model_params': {'im_channels': 3, 'aspect_ratios': [0.5, 1, 2], 'scales': [128, 256, 512], 'min_im_size': 600, 'max_im_size': 1000, 'backbone_out_channels': 512, 'fc_inner_dim': 1024, 'rpn_bg_threshold': 0.3, 'rpn_fg_threshold': 0.7, 'rpn_nms_threshold': 0.7, 'rpn_train_prenms_topk': 12000, 'rpn_test_prenms_topk': 6000, 'rpn_train_topk': 2000, 'rpn_test_topk': 300, 'rpn_batch_size': 256, 'rpn_pos_fraction': 0.5, 'roi_iou_threshold': 0.5, 'roi_low_bg_iou': 0.0, 'roi_pool_size': 7, 'roi_nms_threshold': 0.3, 'roi_topk_detections': 100, 'roi_score_threshold': 0.05, 'roi_batch_size': 128, 'roi_pos_fraction': 0.25}, 'train_params': {'task_name': 'voc', 'seed': 1111, 'acc_steps': 1, 'num_epochs': 4, 'lr_steps': [12, 16], 'lr': 0.001, 'ckpt_name': 'faster_rcnn_voc2007.pth'}}\n",
            "{0: 'background', 1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat', 5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair', 10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse', 14: 'motorbike', 15: 'person', 16: 'pottedplant', 17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor'}\n",
            "100% 4952/4952 [00:11<00:00, 418.82it/s]\n",
            "Total 4952 images found\n",
            "Looking for model at: voc/faster_rcnn_voc2007.pth\n",
            "100% 4951/4952 [09:27<00:00,  8.73it/s]\n",
            "Class Wise Average Precisions\n",
            "AP for class background = nan\n",
            "AP for class aeroplane = 0.2965\n",
            "AP for class bicycle = 0.5722\n",
            "AP for class bird = 0.4504\n",
            "AP for class boat = 0.3243\n",
            "AP for class bottle = 0.0979\n",
            "AP for class bus = 0.3895\n",
            "AP for class car = 0.6157\n",
            "AP for class cat = 0.7036\n",
            "AP for class chair = 0.3066\n",
            "AP for class cow = 0.1556\n",
            "AP for class diningtable = 0.4229\n",
            "AP for class dog = 0.5161\n",
            "AP for class horse = 0.5678\n",
            "AP for class motorbike = 0.5835\n",
            "AP for class person = 0.5865\n",
            "AP for class pottedplant = 0.2419\n",
            "AP for class sheep = 0.2851\n",
            "AP for class sofa = 0.3994\n",
            "AP for class train = 0.5886\n",
            "AP for class tvmonitor = 0.0007\n",
            "Mean Average Precision : 0.4052\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find . -name \"losses.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZQctxaIN1tI",
        "outputId": "d6f078aa-2e45-40da-e1fe-da952f837306"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./voc/losses.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "img_dir = '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/JPEGImages'\n",
        "ann_dir = '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/Annotations'\n",
        "\n",
        "img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]\n",
        "ann_files = [f for f in os.listdir(ann_dir) if f.endswith('.xml')]\n",
        "\n",
        "print(\"Images:\", len(img_files))\n",
        "print(\"Annotations:\", len(ann_files))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "ED6AYrFy1vzp",
        "outputId": "d0c49159-8972-41e1-e276-af50f284c46a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/JPEGImages'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0939762feeb4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mann_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/Annotations'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mann_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/COSC83-spring24-25-student-main (6)/COSC83-spring24-25-student-main (5)/COSC83-spring24-25-student-main/assignment3/VOC2007/JPEGImages'"
          ]
        }
      ]
    }
  ]
}